# -*- coding: utf-8 -*-
"""Default Prediction_final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-cgzDSd8-Lu-HXG2k7UYWD49Vm6qVzTz
"""

import pandas as pd

# URL of the dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls"

# Load the dataset using pandas
try:
  data = pd.read_excel(url, header=1)  # Specify header row
  print("Data loaded successfully.")
except Exception as e:
  print(f"An error occurred: {e}")

print(data.head())
print(data.info())

print(data.isnull().sum())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# 1. Summary Statistics
print(data.describe())

# 2. Data Visualization

# Histograms for numerical features
numerical_features = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',
                     'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
                     'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']
for col in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.histplot(data[col], kde=True)  # KDE adds a smooth curve
    plt.title(f'Distribution of {col}')
    plt.show()

# Box plots for numerical features to visualize outliers
for col in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=data[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

# Count plots for categorical features
# Updated categorical_features list with correct column names
categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']
for col in categorical_features:
    plt.figure(figsize=(8, 6))
    sns.countplot(x=data[col])
    plt.title(f'Countplot of {col}')
    plt.show()

# Correlation matrix (heatmap) for numerical features
plt.figure(figsize=(12, 10))
correlation_matrix = data[numerical_features].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# Pairplot for selected numerical features (optional - for a smaller subset)
# sns.pairplot(data[['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1']])
# plt.show()


# 3. Further analysis (example - relationship between LIMIT_BAL and default payment)
plt.figure(figsize=(8, 6))
sns.boxplot(x='default payment next month', y='LIMIT_BAL', data=data)
plt.title('LIMIT_BAL vs. Default Payment')
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
import numpy as np


# 2. Encoding Categorical Features
categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']
data = pd.get_dummies(data, columns=categorical_features, drop_first=True)

# 3. Feature Scaling
numerical_features = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',
                     'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
                     'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']
scaler = StandardScaler()
data[numerical_features] = scaler.fit_transform(data[numerical_features])

# 4. Handling Outliers (Optional - example for 'LIMIT_BAL')
Q1 = data['LIMIT_BAL'].quantile(0.25)
Q3 = data['LIMIT_BAL'].quantile(0.75)
IQR = Q3 - Q1
upper_bound = Q3 + 1.5 * IQR
lower_bound = Q1 - 1.5 * IQR
data['LIMIT_BAL'] = np.clip(data['LIMIT_BAL'], lower_bound, upper_bound)

# Now 'data' is preprocessed!
print(data.head()) # To verify the changes

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split  # Import train_test_split
from imblearn.over_sampling import SMOTE # Make sure SMOTE is imported

# Define your features (X) and target (y)
X = data.drop('default payment next month', axis=1)
y = data['default payment next month']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Apply SMOTE to training data only
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

from sklearn.model_selection import train_test_split

# Initial split into train+validation and test sets
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Split train+validation into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize and train the Logistic Regression model
logreg_model = LogisticRegression(random_state=42, max_iter=1000) # Increased max_iter
logreg_model.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = logreg_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

from sklearn.metrics import roc_curve, auc

# Calculate ROC curve and AUC
y_pred_proba = logreg_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()


# Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Define model with class weights
log_reg = LogisticRegression(class_weight='balanced', random_state=42)

# Hyperparameter tuning
param_grid = {'C': [0.01, 0.1, 1, 10, 100]}
grid_search = GridSearchCV(log_reg, param_grid, scoring='roc_auc', cv=5)
grid_search.fit(X_train_resampled, y_train_resampled)

# Best model
best_log_reg = grid_search.best_estimator_

# Print the best parameters and score from the GridSearchCV
print("Best parameters:", grid_search.best_params_)
print("Best ROC AUC score:", grid_search.best_score_)

# Make predictions on the test set using the best model
y_pred_proba = best_log_reg.predict_proba(X_test)[:, 1]

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV

# Define model with class weights
rf = RandomForestClassifier(class_weight='balanced', random_state=42)

# Hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_leaf': [1, 2, 4]
}
random_search = RandomizedSearchCV(rf, param_grid, scoring='roc_auc', cv=5, n_iter=10)
random_search.fit(X_train_resampled, y_train_resampled)

# Best model
best_rf = random_search.best_estimator_

# --- Results ---
from sklearn.metrics import classification_report, roc_auc_score # Import necessary functions

print("Best Hyperparameters:", random_search.best_params_)
print("Best ROC-AUC Score (Validation):", random_search.best_score_)

# Predictions on Test Set
y_pred_rf = best_rf.predict(X_test)
y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]  # Probabilities for AUC

# Performance Metrics
print("\nTest Set Performance:")
print(classification_report(y_test, y_pred_rf))
print("ROC-AUC Score (Test):", roc_auc_score(y_test, y_pred_proba_rf))

# Calculate ROC curve and AUC for the Random Forest model
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_proba_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

# Plot ROC curve for the Random Forest model
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'Random Forest ROC curve (area = {roc_auc_rf:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest')
plt.legend(loc='lower right')
plt.show()

from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

# Define model with scale_pos_weight to handle class imbalance
scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)
xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42)

# Hyperparameter tuning
param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 0.9, 1.0]
}
grid_search = GridSearchCV(xgb, param_grid, scoring='roc_auc', cv=5)
grid_search.fit(X_train_resampled, y_train_resampled)

# Best model
best_xgb = grid_search.best_estimator_

# --- Results for XGBoost ---
print("\n--- XGBoost Results ---")
print("Best Hyperparameters:", random_search.best_params_)
print("Best ROC-AUC Score (Validation):", random_search.best_score_)

# Predictions on Test Set
y_pred_xgb = best_xgb.predict(X_test)
y_pred_proba_xgb = best_xgb.predict_proba(X_test)[:, 1]

# Performance Metrics
print("\nTest Set Performance:")
print(classification_report(y_test, y_pred_xgb))
print("ROC-AUC Score (Test):", roc_auc_score(y_test, y_pred_proba_xgb))

# Calculate ROC curve and AUC for the XGBoost model
y_pred_proba_xgb = best_xgb.predict_proba(X_test)[:, 1]
fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, y_pred_proba_xgb)
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)

# Plot ROC curve for XGBoost
plt.figure(figsize=(8, 6))
plt.plot(fpr_xgb, tpr_xgb, color='green', lw=2, label=f'XGBoost ROC curve (area = {roc_auc_xgb:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for XGBoost')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, roc_auc_score
from xgboost import XGBClassifier

# Assuming you have already trained and saved your models (best_log_reg, best_rf, best_xgb)
# If not, you'll need to train them first using the code provided in the previous response.

def predict_default_all_models(input_data):
    """Predicts credit card default using all three models."""

    # Create a DataFrame from user input
    input_df = pd.DataFrame([input_data])

    # Preprocessing
    categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']
    numerical_features = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',
                         'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
                         'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']

    input_df = pd.get_dummies(input_df, columns=categorical_features, drop_first=True)

    # Ensure all columns present in training set are in user input
    for col in X_train.columns:  # Replace X_train with your actual training data
        if col not in input_df.columns:
            input_df[col] = 0  # Fill missing with zero if the user does not input those values.

    # Reorder columns to match training data
    input_df = input_df[X_train.columns]

    scaler = StandardScaler()
    input_df[numerical_features] = scaler.fit_transform(input_df[numerical_features])

    # Make predictions
    logreg_prediction = best_log_reg.predict(input_df)[0]
    rf_prediction = best_rf.predict(input_df)[0]
    xgb_prediction = best_xgb.predict(input_df)[0]

    return {
        'Logistic Regression': logreg_prediction,
        'Random Forest': rf_prediction,
        'XGBoost': xgb_prediction
    }

# Get user input
user_input = {}
features = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',
            'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
            'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
            'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']

for feature in features:
    while True:
        try:
            user_input[feature] = int(input(f"Enter value for {feature}: "))
            break
        except ValueError:
            print("Invalid input. Please enter an integer.")

# Make predictions and print results
predictions = predict_default_all_models(user_input)

print("\nPredictions:")
for model, prediction in predictions.items():
    print(f"{model}: {'Default' if prediction == 1 else 'No Default'}")2

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# Define model with scale_pos_weight to handle class imbalance
scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)
xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=42)

# Hyperparameter tuning using RandomizedSearchCV for faster execution
param_dist = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 0.9, 1.0],
    'n_estimators': [100, 200] # Add n_estimators to search space
}
random_search = RandomizedSearchCV(xgb, param_distributions=param_dist,
                                   n_iter=6, scoring='roc_auc', cv=3,
                                   random_state=42, n_jobs=-1) # Reduce n_iter and cv
random_search.fit(X_train_resampled, y_train_resampled)

# Best model
best_xgb = random_search.best_estimator_